{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook will take the cnn_wide.csv dataset and create a similar one that makes it take into account the previous second.  240xN --> 480xN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import script as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116090, 243)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_csv(r\"C:\\Users\\yashm\\Google Drive\\Data Capstone_\\Project Folder\\PreWideData\\cnn_wide.csv\")\n",
    "data = pd.read_csv(r'C:/Users/Hans/Documents/CalPoly4thYear/Data451/cnn_wide.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>labels</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.621</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>0.590</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.609</td>\n",
       "      <td>0.918</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.602</td>\n",
       "      <td>0.891</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.512</td>\n",
       "      <td>0.914</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.918</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>0.914</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.613</td>\n",
       "      <td>-0.680</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.598</td>\n",
       "      <td>-0.680</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.672</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.586</td>\n",
       "      <td>-0.648</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.582</td>\n",
       "      <td>-0.621</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.473</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.434</td>\n",
       "      <td>-0.895</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.898</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.426</td>\n",
       "      <td>-0.879</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.859</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.465</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.445</td>\n",
       "      <td>-0.859</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.848</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.848</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.438</td>\n",
       "      <td>-0.848</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.418</td>\n",
       "      <td>-0.801</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.422</td>\n",
       "      <td>-0.801</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time      0      1      2      3      4      5      6      7      8  \\\n",
       "0   0.0 -0.605  0.617  0.070 -0.621  0.602  0.023 -0.605  0.590 -0.016   \n",
       "1   1.0 -0.512  0.914 -0.191 -0.441  0.918 -0.152 -0.391  0.914 -0.102   \n",
       "2   2.0 -0.672  0.711  0.586 -0.648  0.684  0.582 -0.621  0.668  0.574   \n",
       "3   3.0 -0.898  0.379  0.426 -0.879  0.387  0.441 -0.859  0.402  0.445   \n",
       "4   4.0 -0.848  0.395  0.441 -0.848  0.379  0.438 -0.848  0.367  0.426   \n",
       "\n",
       "     ...       232    233    234    235    236    237    238    239  labels  \\\n",
       "0    ...     0.934 -0.133 -0.609  0.918 -0.191 -0.602  0.891 -0.195       0   \n",
       "1    ...     0.723  0.613 -0.680  0.727  0.598 -0.680  0.719  0.586       0   \n",
       "2    ...     0.359  0.473 -0.867  0.359  0.434 -0.895  0.363  0.422       0   \n",
       "3    ...     0.402  0.465 -0.875  0.398  0.445 -0.859  0.391  0.441       0   \n",
       "4    ...     0.496  0.418 -0.801  0.496  0.422 -0.801  0.492  0.422       0   \n",
       "\n",
       "   activity  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform into 160x3 columns (create lag)\n",
    "data[np.arange(240,480).astype(str)] = data[np.arange(240).astype(str)].shift(-1)\n",
    "data[['time','activity','labels']] = data[['time','activity','labels']].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    64311\n",
       "3.0    22966\n",
       "2.0    13337\n",
       "1.0     8557\n",
       "6.0     5651\n",
       "4.0      840\n",
       "5.0      427\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for c in data.columns:\n",
    "#     print (c)\n",
    "data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data.index[len(data) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data.sample(int(len(data)*.7))\n",
    "test = data.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train['activity']\n",
    "K = len(train['activity'].unique())\n",
    "features = train[np.arange(480).astype(str)]\n",
    "# features = train[train.columns[1:-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81262, 480), 81262, 2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, len(labels), K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.81599998  0.93400002 -0.83200002]\n",
      "  [-0.85500002  0.92199999 -0.87099999]\n",
      "  [-0.73000002  0.852      -0.87099999]\n",
      "  ..., \n",
      "  [-0.51999998  0.83999997  0.125     ]\n",
      "  [-0.54699999  0.86299998  0.168     ]\n",
      "  [-0.60500002  0.88300002  0.17200001]]\n",
      "\n",
      " [[-0.41800001  0.215      -0.852     ]\n",
      "  [ 0.19499999  0.37099999 -0.71100003]\n",
      "  [ 0.76599997  0.50400001 -0.699     ]\n",
      "  ..., \n",
      "  [ 0.50800002  0.086       0.67199999]\n",
      "  [ 0.42199999  0.09        0.85500002]\n",
      "  [ 0.414       0.039       1.01199996]]\n",
      "\n",
      " [[ 0.60500002  0.523      -0.64099997]\n",
      "  [ 0.58200002  0.53500003 -0.64099997]\n",
      "  [ 0.56300002  0.54699999 -0.64499998]\n",
      "  ..., \n",
      "  [ 0.52700001  0.574      -0.65200001]\n",
      "  [ 0.50800002  0.57800001 -0.65200001]\n",
      "  [ 0.5         0.57800001 -0.66000003]]\n",
      "\n",
      " ..., \n",
      " [[ 0.125       0.98000002  0.117     ]\n",
      "  [ 0.125       0.949       0.105     ]\n",
      "  [ 0.125       0.926       0.082     ]\n",
      "  ..., \n",
      "  [ 0.223       0.96499997  0.102     ]\n",
      "  [ 0.215       0.96899998  0.102     ]\n",
      "  [ 0.215       0.96499997  0.098     ]]\n",
      "\n",
      " [[-0.85900003 -0.5        -0.391     ]\n",
      "  [-0.801      -0.50800002 -0.34799999]\n",
      "  [-0.78100002 -0.523      -0.32800001]\n",
      "  ..., \n",
      "  [-0.78100002 -0.27000001 -0.63700002]\n",
      "  [-0.73799998 -0.30500001 -0.62900001]\n",
      "  [-0.71499997 -0.34       -0.62099999]]\n",
      "\n",
      " [[ 0.875       0.41800001 -0.094     ]\n",
      "  [ 0.82800001  0.43000001 -0.12899999]\n",
      "  [ 0.80900002  0.44499999 -0.125     ]\n",
      "  ..., \n",
      "  [ 0.801       0.465      -0.117     ]\n",
      "  [ 0.80900002  0.461      -0.105     ]\n",
      "  [ 0.852       0.43399999 -0.059     ]]]\n"
     ]
    }
   ],
   "source": [
    "# This is a sanity check to make sure TensorFlow is reshaping the features \n",
    "# into the 3 channels (x, y, z) correctly.\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    train_features = tf.placeholder(tf.float32, shape=(None, 480))\n",
    "    x = tf.reshape(train_features, [-1, 160, 3])\n",
    "    \n",
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(x, feed_dict={train_features: features}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Acc:  52.4033367634  Change:  52.4033367634\n",
      "Epoch:  1  Acc:  55.7960689068  Change:  3.3927321434\n",
      "Epoch:  2  Acc:  62.6012146473  Change:  6.80514574051\n",
      "Epoch:  3  Acc:  66.9648766518  Change:  4.36366200447\n",
      "Epoch:  4  Acc:  69.1331744194  Change:  2.16829776764\n",
      "Epoch:  5  Acc:  70.2443957329  Change:  1.11122131348\n",
      "Epoch:  6  Acc:  70.6603348255  Change:  0.415939092636\n",
      "Epoch:  7  Acc:  70.7464754581  Change:  0.0861406326294\n",
      "Epoch:  8  Acc:  70.8080053329  Change:  0.0615298748016\n",
      "Epoch:  9  Acc:  70.7021713257  Change:  -0.105834007263\n",
      "Epoch:  10  Acc:  70.5963432789  Change:  -0.105828046799\n",
      "Epoch:  11  Acc:  70.6295669079  Change:  0.0332236289978\n",
      "Epoch:  12  Acc:  70.6517219543  Change:  0.022155046463\n",
      "Epoch:  13  Acc:  70.7021713257  Change:  0.0504493713379\n",
      "Epoch:  14  Acc:  70.7956969738  Change:  0.0935256481171\n",
      "Epoch:  15  Acc:  70.9002971649  Change:  0.104600191116\n",
      "Epoch:  16  Acc:  70.9864377975  Change:  0.0861406326294\n",
      "Epoch:  17  Acc:  71.1082696915  Change:  0.121831893921\n",
      "Epoch:  18  Acc:  71.1993277073  Change:  0.0910580158234\n",
      "Epoch:  19  Acc:  71.3100850582  Change:  0.110757350922\n",
      "Epoch:  20  Acc:  71.345770359  Change:  0.035685300827\n",
      "Epoch:  21  Acc:  71.4011490345  Change:  0.0553786754608\n",
      "Epoch:  22  Acc:  71.4848279953  Change:  0.0836789608002\n",
      "Epoch:  23  Acc:  71.5500473976  Change:  0.0652194023132\n",
      "Epoch:  24  Acc:  71.6103494167  Change:  0.0603020191193\n",
      "Epoch:  25  Acc:  71.6251134872  Change:  0.0147640705109\n",
      "Epoch:  26  Acc:  71.6411113739  Change:  0.0159978866577\n",
      "Epoch:  27  Acc:  71.6891050339  Change:  0.0479936599731\n",
      "Epoch:  28  Acc:  71.8121647835  Change:  0.123059749603\n",
      "Epoch:  29  Acc:  71.8798458576  Change:  0.0676810741425\n",
      "Epoch:  30  Acc:  71.9512224197  Change:  0.0713765621185\n",
      "Epoch:  31  Acc:  72.075510025  Change:  0.124287605286\n",
      "Epoch:  32  Acc:  72.1333444118  Change:  0.0578343868256\n",
      "Epoch:  33  Acc:  72.1837997437  Change:  0.0504553318024\n",
      "Epoch:  34  Acc:  72.2244083881  Change:  0.0406086444855\n",
      "Epoch:  35  Acc:  72.2859382629  Change:  0.0615298748016\n",
      "Epoch:  36  Acc:  72.3253190517  Change:  0.0393807888031\n",
      "Epoch:  37  Acc:  72.3806917667  Change:  0.0553727149963\n",
      "Epoch:  38  Acc:  72.4852919579  Change:  0.104600191116\n",
      "Epoch:  39  Acc:  72.4914491177  Change:  0.0061571598053\n",
      "Epoch:  40  Acc:  72.5615918636  Change:  0.0701427459717\n",
      "Epoch:  41  Acc:  72.6095855236  Change:  0.0479936599731\n",
      "Epoch:  42  Acc:  72.6181983948  Change:  0.00861287117004\n",
      "Epoch:  43  Acc:  72.6132750511  Change:  -0.00492334365845\n",
      "Epoch:  44  Acc:  72.6661920547  Change:  0.0529170036316\n",
      "Epoch:  45  Acc:  72.7154135704  Change:  0.0492215156555\n",
      "Epoch:  46  Acc:  72.7363348007  Change:  0.0209212303162\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "learning_rate = 0.08\n",
    "\n",
    "activation_func = tf.tanh\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Placeholders for the actual data.\n",
    "    train_features = tf.placeholder(tf.float32, shape=(None, 480))\n",
    "    train_labels = tf.placeholder(tf.int32, shape=(None, ))\n",
    "    \n",
    "    # Reshaping the data\n",
    "    x = tf.reshape(train_features, [-1, 160, 3])\n",
    "    y = tf.one_hot(\n",
    "        train_labels,\n",
    "        depth=K\n",
    "    )\n",
    "    \n",
    "    # Convolution 1\n",
    "    conv1 = tf.layers.conv1d(inputs=x, \n",
    "                             filters=8, \n",
    "                             kernel_size=8, \n",
    "                             padding=\"same\", \n",
    "                             data_format=\"channels_last\",\n",
    "                             activation=activation_func)\n",
    "    # Max Pooling 1 (reduces samples from 80 --> 31)\n",
    "    pool1 = tf.layers.max_pooling1d(inputs=conv1,\n",
    "                                    pool_size=40, \n",
    "                                    strides=20,\n",
    "                                    data_format=\"channels_last\")\n",
    "    \n",
    "    # Convolution 2\n",
    "    conv2 = tf.layers.conv1d(inputs=pool1, \n",
    "                             filters=16, \n",
    "                             kernel_size=8, \n",
    "                             padding=\"same\", \n",
    "                             data_format=\"channels_last\",\n",
    "                             activation=activation_func)\n",
    "    # Max Pooling 2 (reduces samples from 39 --> 17)\n",
    "    pool2 = tf.layers.max_pooling1d(inputs=conv2,\n",
    "                                    pool_size=2, \n",
    "                                    strides=1,\n",
    "                                    data_format=\"channels_last\")\n",
    "    \n",
    "    # Flatten the Pooled Data\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 6 * 16])\n",
    "    \n",
    "    # Dense Layer (try adding dropout?)\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=128, activation=activation_func)\n",
    "    \n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dense, units=K)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=logits, \n",
    "            labels=y\n",
    "        )\n",
    "    )\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    # Define accuracy (so that it can be calculated and printed)\n",
    "    accuracy = tf.reduce_mean(\n",
    "        tf.cast(\n",
    "            tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1)),\n",
    "            tf.float32\n",
    "        )\n",
    "    )\n",
    "    \n",
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    i = 0\n",
    "    prev = 0\n",
    "    for _ in range(num_epochs):\n",
    "        feed_dict = {\n",
    "            train_features: features,\n",
    "            train_labels: labels\n",
    "        }\n",
    "        _, _, acc = sess.run(\n",
    "            [optimizer, loss, accuracy], \n",
    "            feed_dict=feed_dict)\n",
    "        print(\"Epoch: \", i, \" Acc: \", acc*100, \" Change: \", (acc-prev)*100)\n",
    "        i = i + 1\n",
    "        prev = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
